{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/aouadt/these/projets/3d_segm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import random\n",
    "from functools import reduce\n",
    "from os.path import join\n",
    "from time import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import skimage.morphology as morp\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from PIL import Image, ImageDraw\n",
    "import torchviz\n",
    "from deep_morpho.datasets.mnist_dataset import MnistClassifDataset\n",
    "from deep_morpho.models import LightningBiMoNNClassifier, BiSE, COBiSE, BiSEC, COBiSEC\n",
    "\n",
    "\n",
    "import deep_morpho.models.softplus as sfp\n",
    "import general.array_morphology as arm\n",
    "import general.structuring_elements as selm\n",
    "from general.nn.loss import DiceLoss\n",
    "import deep_morpho.threshold_fn as threshold_fn\n",
    "import deep_morpho.morp_operations as morpop\n",
    "import deep_morpho.models.threshold_layer as threshold_layer\n",
    "import deep_morpho.models.complementation_layer as complementation_layer\n",
    "import deep_morpho.models.pconv as pconv\n",
    "import deep_morpho.models.lightning_pconv as lpconv\n",
    "import deep_morpho.models.bise as bise\n",
    "import deep_morpho.models.lui as lui\n",
    "import deep_morpho.models.bisel as bisel\n",
    "import deep_morpho.models.cobise as cobise\n",
    "import deep_morpho.models.dilation_sum_layer as dis\n",
    "import deep_morpho.models.bimonn as bimonn\n",
    "import deep_morpho.models as models\n",
    "import deep_morpho.models.lightning_bise as lbise\n",
    "import deep_morpho.models.lightning_cobise as lcobise\n",
    "import deep_morpho.models.lightning_bimonn as lbimonn\n",
    "import deep_morpho.datasets.generate_forms1 as gfo\n",
    "import deep_morpho.datasets.generate_forms2 as gfo2\n",
    "import deep_morpho.datasets.generate_forms3 as gfo3\n",
    "import deep_morpho.datasets.axspa_roi_dataset as axd\n",
    "import deep_morpho.datasets.multi_rect_dataset as mrda\n",
    "import deep_morpho.datasets.mnist_dataset as mnist_dataset\n",
    "import deep_morpho.observables.plot_parameters as obs_weights\n",
    "import deep_morpho.observables.plot_pred as obs_pred\n",
    "import deep_morpho.observables.weight_histogram as weight_histogram\n",
    "import deep_morpho.observables as obs\n",
    "import general.nn.viz.plot_histogram as phist\n",
    "import general.nn.viz.element_image as eltimage\n",
    "import general.nn.viz.element_histogram as elthistogram\n",
    "import deep_morpho.viz.morp_operations_viz as mov\n",
    "import deep_morpho.viz.elt_generator_bimonn_forward_save as eltgenbifor\n",
    "import deep_morpho.viz.elt_generator_bimonn_histogram as eltgenbihist\n",
    "import deep_morpho.viz.bimonn_viz as bimonn_viz\n",
    "import deep_morpho.save_results_template.display_results as dr\n",
    "\n",
    "def reload_modules():\n",
    "    for modl in [sfp, arm, selm, threshold_fn, morpop,\n",
    "                 threshold_layer,complementation_layer, pconv, lpconv, bise, lui, bisel, cobise,\n",
    "                 dis, bimonn, models, lbise, lbimonn, lcobise, gfo, gfo2, gfo3, axd,\n",
    "                 mrda, mnist_dataset, obs_weights, obs_pred, obs,\n",
    "                weight_histogram, phist, eltimage, elthistogram, mov, eltgenbifor, eltgenbihist, bimonn_viz, dr]:\n",
    "        reload(modl)\n",
    "        \n",
    "reload_modules()\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "# tb_path = (\"deep_morpho/results/DGMM_2022/sandbox/1/axspa_roi/version_7\")\n",
    "# tb_path = \"/hdd/aouadt/these/projets/3d_segm/deep_morpho/results/results_tensorboards/Bimonn_exp_56/sandbox/2/softplus/diskorect/opening/disk/version_1\"\n",
    "# tb_path = \"deep_morpho/results/results_tensorboards/Bimonn_exp_59/sandbox/0/softplus/diskorect/translation_erosion/hstick/version_0\"\n",
    "tb_path = \"deep_morpho/results/results_tensorboards/Bimonn_exp_59/sandbox/0/softplus/diskorect/translation_erosion/dcross/version_0\"\n",
    "\n",
    "tb_path = join(tb_path, 'checkpoints', os.listdir(join(tb_path, 'checkpoints'))[0])\n",
    "\n",
    "model = models.LightningBiMoNN.load_from_checkpoint(tb_path)\n",
    "model.to(device)\n",
    "\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Experiments comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir_joined(folder: str):\n",
    "    return [os.path.join(folder, k) for k in os.listdir(folder)]\n",
    "\n",
    "path_global = \"deep_morpho/results/results_tensorboards/Bimonn_mega_multi_1/softplus/diskorect/\"\n",
    "all_paths = []\n",
    "for operation in os.listdir(path_global):\n",
    "    if os.path.isdir(join(path_global, operation)):\n",
    "        for selem in os.listdir(join(path_global, operation)):\n",
    "            all_paths += sorted(list_dir_joined(join(path_global, operation, selem)), key=lambda x: int(\n",
    "                re.findall(r'version_(\\d+)$', x)[0]\n",
    "            ))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading results: 100%|██████████| 266/266 [00:08<00:00, 31.73it/s]\n"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "results = dr.DisplayResults().get_all_results_from_tensorboard(all_paths, load_long_args=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "616f52fbe5c706563a560a0f264b4efceff38c19b25b56b7556be5a074dc2458"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
