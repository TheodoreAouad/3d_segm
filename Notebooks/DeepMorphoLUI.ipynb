{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1507d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/aouadt/these/projets/3d_segm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597bc55",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6957c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Callable, List\n",
    "from importlib import reload\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from general.nn.observables import CalculateAndLogMetrics\n",
    "import deep_morpho.observables.save_loss as save_loss\n",
    "import deep_morpho.observables.plot_lui_parameters as plp\n",
    "import deep_morpho.observables.plot_pred as plot_pred \n",
    "import deep_morpho.observables.convergence_steps as convergence_steps \n",
    "import deep_morpho.observables as obs\n",
    "import deep_morpho.datasets.generate_forms3 as gfo3\n",
    "import deep_morpho.datasets.multi_rect_dataset as mrd\n",
    "import deep_morpho.models.lui as lui \n",
    "from general.nn.pytorch_lightning_module.obs_lightning_module import NetLightning\n",
    "from deep_morpho.metrics import dice\n",
    "import general.array_morphology as am\n",
    "from general.structuring_elements import *\n",
    "import deep_morpho.morp_operations as mo\n",
    "\n",
    "\n",
    "def reload_modules():\n",
    "    for modl in [save_loss, plp, plot_pred, convergence_steps, obs, gfo3, mrd, lui, am, mo]:\n",
    "        reload(modl)\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ff59e",
   "metadata": {},
   "source": [
    "##### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66812c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(ars, axis=-1):\n",
    "    return ars.sum(axis) == ars.shape[axis]\n",
    "\n",
    "def union(ars, axis=-1):\n",
    "    return ars.sum(axis) > 0\n",
    "\n",
    "def fn_chans(ar, fn, chans='all'):\n",
    "    if chans == 'all':\n",
    "        chans = range(ar.shape[-1])\n",
    "    return torch.tensor(fn(np.stack([ar[..., chan] for chan in chans], axis=-1)))\n",
    "\n",
    "def intersection_chans(ar, chans='all'):\n",
    "    return fn_chans(ar, intersection, chans)\n",
    "\n",
    "def union_chans(ar, chans='all'):\n",
    "    return fn_chans(ar, union, chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42583061",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "605d6402",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "\n",
    "dataloader = mrd.InputOutputGeneratorDataset.get_loader(\n",
    "    batch_size=32, n_inputs=10000, random_gen_fn=gfo3.get_random_diskorect_channels,\n",
    "    random_gen_args={\n",
    "        \"size\": (50, 50, 3),\n",
    "        \"max_shape\": (50, 50),\n",
    "        \"n_shapes\": 1,\n",
    "        \"p_invert\": 0,\n",
    "        \"n_holes\": 0,\n",
    "        \"noise_proba\": 0\n",
    "    }, morp_operation=lambda x: union_chans(x, chans=[0, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a948cca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd4168ea90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs, outs = next(iter(dataloader))\n",
    "img, out = imgs[0], outs[0]\n",
    "\n",
    "fig, axs = plt.subplots(1, img.shape[-1] + 1)\n",
    "for idx in range(img.shape[-1]):\n",
    "    axs[idx].imshow(img[..., idx], cmap='gray')\n",
    "    \n",
    "axs[img.shape[-1]].imshow(out, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35107ffb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "model = lui.LUI(threshold_mode=\"tanh\", chan_inputs=3, chan_outputs=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7895ca58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BCELoss()(model(imgs).squeeze(), outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e69763",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba759fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "class LightningLUI(NetLightning):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_args: Dict,\n",
    "        learning_rate: float,\n",
    "        loss: Callable,\n",
    "        optimizer: Callable,\n",
    "        output_dir: str,\n",
    "        optimizer_args: Dict = {},\n",
    "        observables: List[\"Observable\"] = [],\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model=lui.LUI(**model_args),\n",
    "            learning_rate=learning_rate,\n",
    "            loss=loss,\n",
    "            optimizer=optimizer,\n",
    "            output_dir=output_dir,\n",
    "            optimizer_args=optimizer_args,\n",
    "            observables=observables,\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # new_hparams = {}\n",
    "        # for key, value in self.hparams.items():\n",
    "        #     if isinstance(value, dict):\n",
    "        #         for key2, value2 in value.items():\n",
    "        #             new_hparams[f'{key}/{key2}'] = value2\n",
    "        # self.hparams.update(new_hparams)\n",
    "\n",
    "    def obs_training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x).squeeze()\n",
    "\n",
    "        outputs = {}\n",
    "\n",
    "        loss_supervised = self.loss(predictions, y)\n",
    "        outputs['loss'] = loss_supervised\n",
    "\n",
    "        return outputs, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17b40b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "\n",
    "def train_lui(args):\n",
    "    dataloader = mrd.InputOutputGeneratorDataset.get_loader(\n",
    "        batch_size=args['batch_size'], n_inputs=args['n_inputs'], \n",
    "        random_gen_fn=gfo3.get_random_diskorect_channels,\n",
    "        random_gen_args={\n",
    "            \"size\": args[\"size\"],\n",
    "            \"max_shape\": args[\"max_shape\"],\n",
    "            \"n_shapes\": args[\"n_shapes\"],\n",
    "            \"p_invert\": args[\"p_invert\"],\n",
    "            \"n_holes\": args[\"n_holes\"],\n",
    "            \"noise_proba\": args[\"noise_proba\"],\n",
    "        }, morp_operation=args['morp_operation'],\n",
    "        num_workers=args['num_workers']\n",
    "    )\n",
    "    logger = TensorBoardLogger(\"deep_morpho/results\", name=args['name'], default_hp_metric=False)\n",
    "    print(f\"Tb path: {logger.log_dir}\")\n",
    "    metrics = {'dice': lambda y_true, y_pred: dice(y_true, y_pred, threshold=.5).mean()}\n",
    "\n",
    "    observables = [\n",
    "        obs.SaveLoss(),\n",
    "        CalculateAndLogMetrics(metrics=metrics, keep_preds_for_epoch=False),\n",
    "        obs.PlotPreds(freq=args['freq_imgs']),\n",
    "        obs.ConvergenceMetrics(metrics),\n",
    "        obs.PlotLUIParameters(),\n",
    "    ]\n",
    "\n",
    "    model = LightningLUI(\n",
    "        model_args={\n",
    "            \"threshold_mode\": args['threshold_mode'],\n",
    "            \"chan_inputs\": args['size'][-1],\n",
    "            \"chan_outputs\": 1,\n",
    "        },\n",
    "        loss=args['loss'],\n",
    "        optimizer=args['optimizer'],\n",
    "        learning_rate=args['lr'],\n",
    "        output_dir=logger.log_dir,\n",
    "        observables=observables.copy()\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=1,\n",
    "        gpus=1,\n",
    "        logger=logger,\n",
    "        callbacks=observables.copy(),\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "    trainer.fit(model, dataloader) \n",
    "    for observable in observables:\n",
    "        observable.save(join(trainer.log_dir, 'observables'))\n",
    "    return dataloader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "970f200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | LUI     | 5     \n",
      "1 | loss  | BCELoss | 0     \n",
      "----------------------------------\n",
      "5         Trainable params\n",
      "0         Non-trainable params\n",
      "5         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tb path: deep_morpho/results/Bimonn_exp_35/version_4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf55902e1ec421bbb9e0c46a0ef5555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'join' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e965148ed02a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-b40791cb7226>\u001b[0m in \u001b[0;36mtrain_lui\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobservable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobservables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mobservable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'observables'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'join' is not defined"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "\n",
    "args = {\n",
    "    \"name\": \"Bimonn_exp_35\",\n",
    "    \"loss\": nn.BCELoss(),\n",
    "    \"optimizer\": optim.Adam,\n",
    "    \"lr\": 1e-3,\n",
    "    \"freq_imgs\": 100,\n",
    "    \"size\": (50, 50, 3),\n",
    "    \"max_shape\": (50, 50),\n",
    "    \"n_shapes\": 5,\n",
    "    \"p_invert\": 0,\n",
    "    \"n_holes\": 0,\n",
    "    \"noise_proba\": 0,\n",
    "    \"batch_size\": 256,\n",
    "    \"n_inputs\": 2_000_000,\n",
    "    \"num_workers\": 20,\n",
    "    \"morp_operation\": lambda x: intersection_chans(x, chans=[0,1]),\n",
    "    \"threshold_mode\": \"tanh\",\n",
    "}\n",
    "\n",
    "dataloader, model = train_lui(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c341acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_str = [\n",
    "    [  # layer 1. Input is one channel, we only put one operation. We output two channels.\n",
    "        [(\"erosion\", disk(3)), \"intersection\"],\n",
    "        [(\"dilation\", disk(3)), \"union\"],\n",
    "    ],\n",
    "    [  # layer 2. Input is two channels, we need two operations per channel. We output three channels.\n",
    "        [(\"erosion\", disk(3)), (\"dilation\", disk(3)), \"union\"],\n",
    "        [(\"dilation\", disk(3)), (\"erosion\", disk(3)), \"intersection\"],\n",
    "        [(\"dilation\", disk(3)), (\"dilation\", disk(3)), \"intersection\"],\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94231e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erodila_selem_converter(args):\n",
    "    str_to_selem_fn = {\n",
    "        'disk': disk, 'vstick': vstick, 'hstick': hstick, 'square': square, \n",
    "        'dcross': dcross, 'scross': scross,\n",
    "        'vertical_stick': vstick, 'horizontal_stick': hstick, \n",
    "        'diagonal_cross': dcross, 'straight_cross': scross,\n",
    "    }\n",
    "    selem_name = None\n",
    "    selem_args = None\n",
    "    if not isinstance(args, tuple):\n",
    "        return args, selem_name, selem_args\n",
    "    if isinstance(args[0], str):\n",
    "        selem_name = args[0]\n",
    "        selem_op = str_to_selem_fn[selem_name]\n",
    "    else:\n",
    "        selem_op = args[0]\n",
    "\n",
    "    selem_args = args[1]\n",
    "    return selem_op(selem_args), selem_name, selem_args\n",
    "\n",
    "def erodila_op_converter(args):\n",
    "    str_to_fn = {'dilation': am.array_dilation, 'erosion': am.array_erosion}\n",
    "    \n",
    "    op_name = None\n",
    "    selem_name = None\n",
    "    selem_args = None\n",
    "    \n",
    "    if not isinstance(args, tuple):\n",
    "        return args, op_name, selem_name, selem_args\n",
    "\n",
    "    if isinstance(args[0], str):\n",
    "        op_name = args[0]\n",
    "        op_fn = str_to_fn[args[0]]\n",
    "    else:\n",
    "        op_fn = args[0]\n",
    "    \n",
    "    selem, selem_name, selem_args = erodila_selem_converter(args[1])\n",
    "    return lambda x: op_fn(x, selem=selem), op_name, selem_name, selem_args\n",
    "\n",
    "def ui_converter(args):\n",
    "    str_to_fn = {'union': union_chans, 'intersection': intersection_chans}\n",
    "    \n",
    "    ui_name = None\n",
    "    ui_args = \"all\"\n",
    "    \n",
    "    if isinstance(args, tuple):\n",
    "        ui_fn = args[0]\n",
    "        ui_args = args[1]\n",
    "    else:\n",
    "        ui_fn = args\n",
    "    \n",
    "    if isinstance(ui_fn, str):\n",
    "        ui_name = ui_fn\n",
    "        ui_fn = str_to_fn[ui_name]\n",
    "    \n",
    "    return lambda x: ui_fn(x, ui_args), ui_name, ui_args\n",
    "    \n",
    "        \n",
    "def convert_ops(op_str):\n",
    "    res = []\n",
    "    for layer in op_str:\n",
    "        layer_res = []\n",
    "        for chan in layer:\n",
    "            chan_res = []\n",
    "            for op in chan[:-1]:\n",
    "                chan_res.append(erodila_op_converter(op)[0])\n",
    "            chan_res.append(ui_converter(chan[-1])[0])\n",
    "            layer_res.append(chan_res)\n",
    "        res.append(layer_res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2c6ae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>],\n",
       "  [<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>]],\n",
       " [[<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>],\n",
       "  ['dilation',\n",
       "   <function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>],\n",
       "  [<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>]]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_ops(ops_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "080da146",
   "metadata": {},
   "outputs": [],
   "source": [
    "ero = am.array_erosion\n",
    "dil = am.array_dilation\n",
    "uni = union_chans\n",
    "inter = intersection_chans\n",
    "\n",
    "ops_fn = [\n",
    "    [\n",
    "        [lambda x: ero(x, selem=disk(3)), inter],\n",
    "        [lambda x: dil(x, selem=disk(3)), uni],\n",
    "    ],\n",
    "    [\n",
    "        [lambda x: ero(x, selem=disk(3)), lambda x: dil(x, selem=disk(3)), uni],\n",
    "        [lambda x: dil(x, selem=disk(3)), lambda x: ero(x, selem=disk(3)), inter],\n",
    "        [lambda x: dil(x, selem=disk(3)), lambda x: dil(x, selem=disk(3)), inter],\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d665f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_fn = {\n",
    "    'erosion': am.array_erosion,\n",
    "    'dilation': am.array_dilation,\n",
    "    'intersection': intersection_chans,\n",
    "    'union': union_chans,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0de9e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = disk(20)[..., None]\n",
    "\n",
    "def apply_ops(inpt, ops_fn):\n",
    "    x = inpt + 0\n",
    "    for layer in ops_fn:\n",
    "        next_x = np.zeros(x.shape[:-1] + (len(layer),))\n",
    "        for chan_idx, chan in enumerate(layer):\n",
    "            morps, ui = chan[:-1], chan[-1]\n",
    "            next_x[..., chan_idx] = ui(\n",
    "                np.stack([morps[idx](x[..., idx]) for idx in range(len(morps))], axis=-1)\n",
    "            )\n",
    "        x = next_x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67d6b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "otp1 = apply_ops(inpt, ops_fn)\n",
    "otp2 = apply_ops(inpt, convert_ops(ops_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a9f959b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>],\n",
       "  [<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>]],\n",
       " [[<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>],\n",
       "  ['dilation',\n",
       "   <function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>],\n",
       "  [<function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.erodila_op_converter.<locals>.<lambda>(x)>,\n",
       "   <function __main__.ui_converter.<locals>.<lambda>(x)>]]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "convert_ops(ops_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9cf8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "\n",
    "ops_str = [\n",
    "    [  # layer 1. Input is one channel, we only put one operation. We output two channels.\n",
    "        [(\"erosion\", (\"disk\", 3)), \"intersection\"],\n",
    "        [(\"dilation\", (\"disk\", 3)), \"union\"],\n",
    "    ],\n",
    "    [  # layer 2. Input is two channels, we need two operations per channel. We output three channels.\n",
    "        [(\"erosion\", (\"disk\", 3)), (\"dilation\", (\"disk\", 3)), \"union\"],\n",
    "        [(\"dilation\", (\"disk\", 3)), (\"erosion\", (\"disk\", 3)), \"intersection\"],\n",
    "        [(\"dilation\", (\"disk\", 3)), (\"dilation\", (\"disk\", 3)), \"intersection\"],\n",
    "    ]\n",
    "]\n",
    "\n",
    "ops_fn = [\n",
    "    [\n",
    "        [lambda x: ero(x, selem=disk(3)), inter],\n",
    "        [lambda x: dil(x, selem=disk(3)), uni],\n",
    "    ],\n",
    "    [\n",
    "        [lambda x: ero(x, selem=disk(3)), lambda x: dil(x, selem=disk(3)), uni],\n",
    "        [lambda x: dil(x, selem=disk(3)), lambda x: ero(x, selem=disk(3)), inter],\n",
    "        [lambda x: dil(x, selem=disk(3)), lambda x: dil(x, selem=disk(3)), inter],\n",
    "    ],\n",
    "]\n",
    "\n",
    "morp1 = mo.ParallelMorpOperations(ops_str)\n",
    "morp2 = mo.ParallelMorpOperations(ops_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "942c6a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelMorpOperations(in_channels=1, out_channels=3)\n",
       "    Layer0(in_channels=1, out_channels=2)\n",
       "        Out0: inter(chans=all) | erosion(disk(3))\n",
       "        Out1: union(chans=all) | dilation(disk(3))\n",
       "    Layer1(in_channels=2, out_channels=3)\n",
       "        Out0: union(chans=all) | erosion(disk(3)) dilation(disk(3))\n",
       "        Out1: inter(chans=all) | dilation(disk(3)) erosion(disk(3))\n",
       "        Out2: inter(chans=all) | dilation(disk(3)) dilation(disk(3))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20e80f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelMorpOperations(in_channels=1, out_channels=3)\n",
       "    Layer0(in_channels=1, out_channels=2)\n",
       "        Out0: None(chans=all) | None(None(None))\n",
       "        Out1: None(chans=all) | None(None(None))\n",
       "    Layer1(in_channels=2, out_channels=3)\n",
       "        Out0: None(chans=all) | None(None(None)) None(None(None))\n",
       "        Out1: None(chans=all) | None(None(None)) None(None(None))\n",
       "        Out2: None(chans=all) | None(None(None)) None(None(None))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "789b4be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morp1.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9fbbe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_modules()\n",
    "\n",
    "inpt = disk(20)[..., None]\n",
    "\n",
    "(morp1(inpt) - morp2(inpt)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f87e5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[3], [3]], [[3, 3], [3, 3], [3, 3]]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morp1.selem_args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
