{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1507d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/aouadt/these/projets/3d_segm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597bc55",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6957c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Callable, List\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from general.nn.observables import CalculateAndLogMetrics\n",
    "import deep_morpho.observables.save_loss as save_loss\n",
    "import deep_morpho.observables.plot_lui_parameters as plp\n",
    "import deep_morpho.observables.plot_pred as plot_pred \n",
    "import deep_morpho.observables.convergence_steps as convergence_steps \n",
    "import deep_morpho.observables as obs\n",
    "import deep_morpho.datasets.generate_forms3 as gfo3\n",
    "import deep_morpho.datasets.multi_rect_dataset as mrd\n",
    "import deep_morpho.models.lui as lui \n",
    "from general.nn.pytorch_lightning_module.obs_lightning_module import NetLightning\n",
    "from deep_morpho.metrics import dice\n",
    "\n",
    "\n",
    "def reload_modules():\n",
    "    for modl in [save_loss, plp, plot_pred, convergence_steps, obs, gfo3, mrd, lui]:\n",
    "        reload(modl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ff59e",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66812c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(ar1, ar2):\n",
    "    return ar1 + ar2 == 2\n",
    "\n",
    "def union(ar1, ar2):\n",
    "    return ar1 + ar2 > 0\n",
    "\n",
    "def fn_chans(ar, fn, chans='all'):\n",
    "    if chans == 'all':\n",
    "        chans = range(ar.shape[-1])\n",
    "    return torch.tensor(fn(*[ar[..., chan] for chan in chans]))\n",
    "\n",
    "def intersection_chans(ar, chans='all'):\n",
    "    return fn_chans(ar, intersection, chans)\n",
    "\n",
    "def union_chans(ar, chans='all'):\n",
    "    return fn_chans(ar, union, chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42583061",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605d6402",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "\n",
    "dataloader = mrd.InputOutputGeneratorDataset.get_loader(\n",
    "    batch_size=32, n_inputs=10000, random_gen_fn=gfo3.get_random_diskorect_channels,\n",
    "    random_gen_args={\n",
    "        \"size\": (50, 50, 2),\n",
    "        \"max_shape\": (50, 50),\n",
    "        \"n_shapes\": 1,\n",
    "        \"p_invert\": 0,\n",
    "        \"n_holes\": 0,\n",
    "        \"noise_proba\": 0\n",
    "    }, morp_operation=union_chans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a948cca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83181c4880>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs, outs = next(iter(dataloader))\n",
    "img, out = imgs[0], outs[0]\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(img[..., 0], cmap='gray')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(img[..., 1], cmap='gray')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(out, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35107ffb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "model = lui.LUI(threshold_mode=\"tanh\", chan_inputs=2, chan_outputs=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7895ca58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BCELoss()(model(imgs).squeeze(), outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e69763",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba759fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "class LightningLUI(NetLightning):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_args: Dict,\n",
    "        learning_rate: float,\n",
    "        loss: Callable,\n",
    "        optimizer: Callable,\n",
    "        output_dir: str,\n",
    "        optimizer_args: Dict = {},\n",
    "        observables: List[\"Observable\"] = [],\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model=lui.LUI(**model_args),\n",
    "            learning_rate=learning_rate,\n",
    "            loss=loss,\n",
    "            optimizer=optimizer,\n",
    "            output_dir=output_dir,\n",
    "            optimizer_args=optimizer_args,\n",
    "            observables=observables,\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # new_hparams = {}\n",
    "        # for key, value in self.hparams.items():\n",
    "        #     if isinstance(value, dict):\n",
    "        #         for key2, value2 in value.items():\n",
    "        #             new_hparams[f'{key}/{key2}'] = value2\n",
    "        # self.hparams.update(new_hparams)\n",
    "\n",
    "    def obs_training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x).squeeze()\n",
    "\n",
    "        outputs = {}\n",
    "\n",
    "        loss_supervised = self.loss(predictions, y)\n",
    "        outputs['loss'] = loss_supervised\n",
    "\n",
    "        return outputs, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b40b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "\n",
    "def train_lui(args):\n",
    "    dataloader = mrd.InputOutputGeneratorDataset.get_loader(\n",
    "        batch_size=args['batch_size'], n_inputs=args['n_inputs'], \n",
    "        random_gen_fn=gfo3.get_random_diskorect_channels,\n",
    "        random_gen_args={\n",
    "            \"size\": args[\"size\"],\n",
    "            \"max_shape\": args[\"max_shape\"],\n",
    "            \"n_shapes\": args[\"n_shapes\"],\n",
    "            \"p_invert\": args[\"p_invert\"],\n",
    "            \"n_holes\": args[\"n_holes\"],\n",
    "            \"noise_proba\": args[\"noise_proba\"],\n",
    "        }, morp_operation=args['morp_operation'],\n",
    "        num_workers=args['num_workers']\n",
    "    )\n",
    "    logger = TensorBoardLogger(\"deep_morpho/results_lui\", name=\"LUI_exp_1\", default_hp_metric=False)\n",
    "    print(f\"Tb path: {logger.log_dir}\")\n",
    "    metrics = {'dice': lambda y_true, y_pred: dice(y_true, y_pred, threshold=.5).mean()}\n",
    "\n",
    "    observables = [\n",
    "        obs.SaveLoss(),\n",
    "        CalculateAndLogMetrics(metrics=metrics, keep_preds_for_epoch=False),\n",
    "        obs.PlotPreds(freq=args['freq_imgs']),\n",
    "        obs.ConvergenceMetrics(metrics),\n",
    "        obs.PlotLUIParameters(),\n",
    "    ]\n",
    "\n",
    "    model = LightningLUI(\n",
    "        model_args={\n",
    "            \"threshold_mode\": args['threshold_mode'],\n",
    "            \"chan_inputs\": args['size'][-1],\n",
    "            \"chan_outputs\": 1,\n",
    "        },\n",
    "        loss=args['loss'],\n",
    "        optimizer=args['optimizer'],\n",
    "        learning_rate=args['lr'],\n",
    "        output_dir=logger.log_dir,\n",
    "        observables=observables.copy()\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=1,\n",
    "        gpus=1,\n",
    "        logger=logger,\n",
    "        callbacks=observables.copy(),\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "    trainer.fit(model, dataloader) \n",
    "    return dataloader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970f200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/hdd/python_venvs/torchenv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: attribute 'observables' removed from hparams because it cannot be pickled\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/hdd/python_venvs/torchenv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | LUI     | 4     \n",
      "1 | loss  | BCELoss | 0     \n",
      "----------------------------------\n",
      "4         Trainable params\n",
      "0         Non-trainable params\n",
      "4         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tb path: deep_morpho/results_lui/LUI_exp_1/version_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef2af6cf7224b0793aa13ec9db938ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload_modules()\n",
    "\n",
    "args = {\n",
    "    \"loss\": nn.BCELoss(),\n",
    "    \"optimizer\": optim.Adam,\n",
    "    \"lr\": 1e-3,\n",
    "    \"freq_imgs\": 100,\n",
    "    \"size\": (50, 50, 2),\n",
    "    \"max_shape\": (50, 50),\n",
    "    \"n_shapes\": 1,\n",
    "    \"p_invert\": 0,\n",
    "    \"n_holes\": 0,\n",
    "    \"noise_proba\": 0,\n",
    "    \"batch_size\": 256,\n",
    "    \"n_inputs\": 1_000_000,\n",
    "    \"num_workers\": 20,\n",
    "    \"morp_operation\": union_chans,\n",
    "    \"threshold_mode\": \"tanh\",\n",
    "}\n",
    "\n",
    "dataloader, model = train_lui(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f075a0ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8e5a613c14db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "imgs, outs = next(iter(dataloader))\n",
    "preds = model(imgs)\n",
    "\n",
    "img, pred, out = imgs[0], preds[0], outs[0]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(pred.detach(), vmin=0, vmax=1)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c341acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
